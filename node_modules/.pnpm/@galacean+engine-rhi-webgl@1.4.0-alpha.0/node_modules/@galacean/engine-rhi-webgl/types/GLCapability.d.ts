import { GLCapabilityType } from "@galacean/engine-core";
import { WebGLGraphicDevice } from "./WebGLGraphicDevice";
import { GLCompressedTextureInternalFormat } from "./type";
/**
 * GL capability.
 */
export declare class GLCapability {
    private _maxDrawBuffers;
    private _maxAnisoLevel;
    private _maxAntiAliasing;
    _rhi: WebGLGraphicDevice;
    capabilityList: Map<GLCapabilityType, boolean>;
    get maxTextureSize(): boolean;
    get canUseFloatTextureBlendShape(): boolean;
    /**
     * Whether can use more joints.
     */
    get canIUseMoreJoints(): boolean;
    get maxDrawBuffers(): number;
    /**
     * Max anisoLevel.
     */
    get maxAnisoLevel(): number;
    /**
     * Max MSAA count.
     */
    get maxAntiAliasing(): number;
    get rhi(): WebGLGraphicDevice;
    constructor(rhi: WebGLGraphicDevice);
    /**
     * Check device capabilities.
     */
    canIUse(capabilityType: GLCapabilityType): boolean;
    /**
     * Check if can use some compressed texture format.
     */
    canIUseCompressedTextureInternalFormat(internalType: GLCompressedTextureInternalFormat): boolean;
    /**
     *  Init capabilities.
     */
    private _init;
    /**
     * If there are extensions that can supplement this ability, smooth out the difference.
     * @example
     * compatible(GLCapabilityType.depthTexture,{
     *    UNSIGNED_INT_24_8: "UNSIGNED_INT_24_8_WEBGL"
     * })
     * gl.UNSIGNED_INT_24_8 = ext.UNSIGNED_INT_24_8_WEBGL
     */
    private _compatibleInterface;
    private _compatibleAllInterface;
}
